{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f90ceadd-b663-4cf9-8789-ab3e769b20c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Installing all the necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c99c4-5adf-4667-a059-1668ef8efe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94760df-2ee4-4c61-98d7-ddaef64e75e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First upgrade the environment.\n",
    "from subprocess import run\n",
    "# Add & Upgrade whatever you will need\n",
    "modules =[\n",
    "    #'yfinance',    # Required for Yahoo Finance model\n",
    "    'fredapi',     # Required to access FRED Data for MacroEconomics indices\n",
    "    'ta'           # Required for the MACD indicator\n",
    "]\n",
    "proc = run(f'pip install {\" \".join(modules)} --upgrade --no-input', \n",
    "       shell=True, \n",
    "       text=True, \n",
    "       capture_output=True, \n",
    "       timeout=120) #a couple of minutes\n",
    "print(proc.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d67c39-8b30-428b-aec9-979bf0dc9168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Formating {Fore Colors and Background Colors definition}\n",
    "RESET = '\\033[0m'\n",
    "BOLD  = '\\033[1m'\n",
    "ITALIC= \"\\033[3m\"\n",
    "ULINE = '\\033[4m'\n",
    "BLINK = \"\\033[5m\"\n",
    "NEGATIVE = \"\\033[7m\"\n",
    "\n",
    "RED   = '\\033[31m'\n",
    "GREEN = '\\033[32m'\n",
    "YELLOW= '\\033[33m'\n",
    "BLUE  = '\\033[34m'\n",
    "PURPLE= '\\033[35m'\n",
    "CYAN  = '\\033[36m'\n",
    "WHITE = '\\033[97m'\n",
    "\n",
    "BgGREEN = '\\033[42m'\n",
    "BgYELLOW= '\\033[43m'\n",
    "BgBLUE  = '\\033[44m'\n",
    "BgWHITE = '\\033[47m'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c177997a-da84-4d0b-9d69-b96b0514d164",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import All the General and commonly used Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b9ebb2-4a10-4df0-87f4-d8bfeef076cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the common modules\n",
    "import os\n",
    "import warnings\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fredapi import Fred\n",
    "from ta.trend import MACD\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler            #, StandardScaler, Normalizer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64c29b0-091f-4788-96bd-f9f625c695ef",
   "metadata": {},
   "source": [
    "## Defining the reqired funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5051e9-1ae4-4bc1-95c6-35ca2b1cdd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Relative Strength Index (RSI)\n",
    "def Calculate_RSI(data, window=14):\n",
    "    delta = data.diff(1)\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e6b17f-3652-45e0-9985-9e8bbf938a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Exponential Moving Average (EMA)\n",
    "def Calculate_EMA(data, n):\n",
    "    ema_values = [data[0]]  # Initialize EMA list with the first value\n",
    "    smoothing_factor = 2 / (n + 1)\n",
    "    \n",
    "    for i in range(1, len(data)):\n",
    "        ema = (data[i] * smoothing_factor) + (ema_values[i - 1] * (1 - smoothing_factor))\n",
    "        ema_values.append(ema)\n",
    "    \n",
    "    return ema_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec08eb3-40d4-425a-a021-2bce1576a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Average True Range (ATR)\n",
    "def Calculate_ATR(df, period=14):\n",
    "    df['High-Low'] = df['High'] - df['Low']\n",
    "    df['High-PrevClose'] = (df['High'] - df['Price'].shift(1)).abs()\n",
    "    df['Low-PrevClose'] = (df['Low'] - df['Price'].shift(1)).abs()\n",
    "    df['TR'] = df[['High-Low', 'High-PrevClose', 'Low-PrevClose']].max(axis=1)\n",
    "    df['ATR'] = df['TR'].rolling(window=period, min_periods=1).mean()\n",
    "\n",
    "    # Clean up the DataFrame\n",
    "    df.drop(columns=['High-Low', 'High-PrevClose', 'Low-PrevClose', 'TR'], inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff05e77a-b213-4587-9375-60642ec21a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate On Balance Volume (OBV)\n",
    "def Get_Obv(df):\n",
    "    df['Daily Change'] = df['Price'].diff()\n",
    "    df['Volume Direction'] = np.where(df['Daily Change'] >= 0, 1, -1)\n",
    "    df['OBV'] = df['Volume Direction'] * df['Volume']\n",
    "    df.fillna(0, inplace=True)\n",
    "    df['OBV'] = df['OBV'].cumsum()\n",
    "    df.drop(['Daily Change', 'Volume Direction'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17060ba-161d-404d-8373-2fbae0d50007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FillGaps(StartingDate, EndingDate, StartVal, EndVal):\n",
    "    import math\n",
    "\n",
    "    # Generate business days for the year\n",
    "    Business_Days = pd.date_range(start=StartingDate+timedelta(days=1, hours=0), end=EndingDate-timedelta(days=1, hours=0), freq='B')\n",
    "\n",
    "    # Calculate the incremental value\n",
    "    SVal = value = float(StartVal)\n",
    "    EVal = value = float(EndVal)\n",
    "    if (math.isnan(SVal)):\n",
    "        Incremental_Value = 0\n",
    "    elif ((not math.isnan(SVal)) & (math.isnan(EVal))):\n",
    "        Incremental_Value = StartVal\n",
    "    elif ((not math.isnan(SVal)) & (not math.isnan(EVal))):\n",
    "        Incremental_Value = (EndVal - StartVal) / (len(Business_Days) + 1)\n",
    "\n",
    "    return Incremental_Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db07921-f5b7-4dfa-a69d-30215b1ba94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch MacroEconomics data from FRED\n",
    "def Fetch_Series(APIKey, IndName, Series_ID):\n",
    "    #StartDate = pd.to_datetime('1982.01.01')\n",
    "    StartDate = MinDate\n",
    "    EndDate = pd.Timestamp.today().normalize()\n",
    "    Data_Dict = {}\n",
    "    try:\n",
    "        Data = APIKey.get_series(Series_ID, StartDate, EndDate)\n",
    "        Data_Dict[IndName] = Data\n",
    "        Df = pd.DataFrame(Data_Dict)\n",
    "        Df.reset_index(inplace=True)\n",
    "        Df.rename(columns={'index': 'Date'}, inplace=True)\n",
    "        Df.sort_values(by=['Date'], ascending=[True], inplace=True)\n",
    "        MaxDate = Df.Date.max()\n",
    "        DfTmp = Df.copy()\n",
    "        \n",
    "        # MacroEconomic data is maintained on Monthly and Quarterly Bases.\n",
    "        # The following code will fill the Daily gaps in the data with the calibrated incremental values.\n",
    "        for row in range(0, len(Df)-1):\n",
    "            StartDate = DfTmp.iloc[row, 0]\n",
    "            StartVal = DfTmp.iloc[row, 1]\n",
    "            EndDate = DfTmp.iloc[row+1, 0]\n",
    "            EndVal = DfTmp.iloc[row+1, 1]\n",
    "    \n",
    "            IncVal = FillGaps(StartDate, EndDate, StartVal, EndVal)\n",
    "            Business_Days = pd.date_range(start=StartDate+timedelta(days=1, hours=0), end=EndDate-timedelta(days=1, hours=0), freq='B')\n",
    "            Val = StartVal\n",
    "            for BDay in Business_Days:\n",
    "                Val = Val + IncVal\n",
    "                Df.loc[len(Df.index)] = [BDay, Val]\n",
    "    \n",
    "        if (MaxDate < pd.Timestamp.today().normalize()):\n",
    "            StartDate = MaxDate\n",
    "            EndDate = pd.Timestamp.today().normalize()\n",
    "            Business_Days = pd.date_range(start=StartDate+timedelta(days=1, hours=0), end=EndDate-timedelta(days=0, hours=0), freq='B')\n",
    "            Val = EndVal\n",
    "            for BDay in Business_Days:\n",
    "                Val = Val + IncVal\n",
    "                Df.loc[len(Df.index)] = [BDay, Val]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {IndName}: {e}\")\n",
    "    return Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d880dd-2a0f-43b3-9350-275280f2d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestTheModel(Model):\n",
    "    # Checking how good this Model will be\n",
    "    # Forecast day(s) ahead based on Test Data\n",
    "    y_Train_Pred = Model.predict(X_train)\n",
    "    y_Test_Pred = Model.predict(X_test)\n",
    "    \n",
    "    r2_Train = 0.00\n",
    "    r2_Test = 0.00\n",
    "    # Calculate R² error on Training Data and Test Data\n",
    "    r2_Train = r2_score(y_train, y_Train_Pred)\n",
    "    r2_Test = r2_score(y_test, y_Test_Pred)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"R² error on Training Data: {r2_Train:.5f}\")\n",
    "    print(f\"R² error on Test Data: {r2_Test:.5f}\")\n",
    "    \n",
    "    # Confirm that R² error on Training Data is better than R² error on Test Data\n",
    "    if (r2_Train >= r2_Test) & ((1.00 - r2_Train) < 0.1) & ((r2_Train - r2_Test) < 0.2):\n",
    "        if (r2_Test == 1.00):\n",
    "            Comment = 'Excellent Model!'\n",
    "            print(f'{BOLD+GREEN+BgWHITE}{Comment}{RESET}\\n{BOLD+ITALIC+NEGATIVE+BgGREEN}R² error on Training Data equals R² error on Test Data.{RESET}')\n",
    "        elif (r2_Train > r2_Test) & ((1.00 - r2_Train) < 0.0001) & ((r2_Train - r2_Test) < 0.001):\n",
    "            Comment = 'Very Good Model!'\n",
    "            print(f'{BOLD+GREEN+BgWHITE}{Comment}{RESET}\\n{BOLD+ITALIC+NEGATIVE+BgGREEN}R² error on Training Data is better than R² error on Test Data.{RESET}')\n",
    "        elif (r2_Train > r2_Test) & ((1.00 - r2_Train) < 0.001) & ((r2_Train - r2_Test) < 0.01):\n",
    "            Comment = 'Good Model!'\n",
    "            print(f'{BOLD+GREEN+BgWHITE}{Comment}{RESET}\\n{BOLD+ITALIC+NEGATIVE+BgGREEN}R² error on Training Data is better than R² error on Test Data.{RESET}')\n",
    "        else:\n",
    "            Comment = 'Fairly Good Model.'\n",
    "            print(f'{BOLD+BLUE+BgWHITE}{Comment}{RESET}\\n{BOLD+ITALIC+NEGATIVE+BgBLUE}R² error on Training Data is better than R² error on Test Data.{RESET}')\n",
    "    else:\n",
    "        Comment = 'Bad Model.'\n",
    "        print(f'{BOLD+RED+BLINK+BgYELLOW}{Comment}{RESET}')\n",
    "    return r2_Train, r2_Test, Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34962d4c-c2c1-4a33-b6d8-832e3976f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_TrainTest(CrncyPair, Y_Train, Y_Test):\n",
    "    # Plot Train and Test prices\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(Y_Train.index, Y_Train.values, label='Training Data', color='blue')\n",
    "    plt.plot(Y_Test.index, Y_Test.values, label='Test Data', color='orange')\n",
    "    plt.title('The Train/Test data for ' + CrncyPair + ' Forecasting')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb94204-e538-44d9-bfbd-fe5ae9b6c1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rpt_Evaluate_Plot(CrncyPair, Model_Name, Model_Code, R2_Train, R2_Test, Comment, Y_Train, Y_Test, Y_Pred, MaxDate, Future_Preds):\n",
    "    # Evaluate the model\n",
    "    mae = mean_absolute_error(Y_Test, Y_Pred)\n",
    "    print(\"Mean Absolute Error: {:.5f}\".format(mae))\n",
    "    # ============================================\n",
    "    mse = mean_squared_error(Y_Test, Y_Pred)\n",
    "    print(\"Mean Squared Error: {:.5f}\".format(mse))\n",
    "    # ===================================================\n",
    "    rmse = np.sqrt(mse)\n",
    "    print('Root Mean Squared Error: {:.5f}'.format(rmse))\n",
    "    # ============================================\n",
    "    r2 = r2_score(Y_Test, Y_Pred)\n",
    "    print(\"R-squared (R2) score: {:.5f}\".format(r2))\n",
    "    # ============================================\n",
    "    print('Future Predictions', Future_Preds)\n",
    "\n",
    "    # Plotting the graph\n",
    "    Future_Dates = pd.date_range(start=MaxDate+timedelta(days=1), periods=len(Future_Preds), freq=\"B\")\n",
    "\n",
    "    # Plot Actual vs Predicted prices\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(Future_Dates, ActualValues, label='Actual Data', color='green')\n",
    "    plt.plot(Future_Dates, Future_Preds, label='Predicted Data', color='blue')\n",
    "    plt.scatter(Future_Dates, ActualValues, s=10, color='red')\n",
    "    plt.scatter(Future_Dates, Future_Preds, s=10, color='red')\n",
    "    plt.title(Model_Name + ': Actual vs Predicted values for ' + CrncyPair + ' Forecasting')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Inserting Record into the DataFrame\n",
    "    Models_Compare.loc[len(Models_Compare.index)] = [Model_Name, Model_Code, mae, mse, rmse, R2_Train, R2_Test, Comment]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71fb656-ccb6-4b94-9ff4-6625b69300e0",
   "metadata": {},
   "source": [
    "## Load the Currency Pair into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742344fc-5ddd-4f1e-9589-ea1081895fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TDSData = []\n",
    "Investing = []\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Today's Date\n",
    "TDate = pd.Timestamp.today().normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b506eb2a-1311-4cb9-9de6-051f4ab917eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Every Currency Pair is a combination of Major and Minor currency\n",
    "CrncyPair = 'USDCAD'\n",
    "Major = CrncyPair[0:3]\n",
    "Minor = CrncyPair[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b879e87c-d27d-4f74-b93a-59d6d1949871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# My GitHub Data path\n",
    "MyGitHubURL = 'https://raw.githubusercontent.com/Akubue4U/PyProjects/main/MyBDAThesis/'\n",
    "\n",
    "# DATA SOURCE 01 (Investing Data stored in GitHub)\n",
    "# ================================================\n",
    "# Reading data from csv file, which was uploaded to GitHub.\n",
    "# Data was downloaded from the link below, and saved as .csv\n",
    "# https://www.investing.com/currencies/usd-cad-historical-data\n",
    "DataFolder = 'InvestingData/'\n",
    "Base_URL = MyGitHubURL + DataFolder\n",
    "InvCrncyPair = Major +'_'+ Minor\n",
    "InvFileName = InvCrncyPair + '_Historical_Data'\n",
    "\n",
    "# Check if the URL exists and is accessible\n",
    "SuccessCode = [200, 400]\n",
    "response = requests.head(Base_URL, timeout=5)\n",
    "try:\n",
    "    #if response.status_code in SuccessCode:\n",
    "    File_URL = f'{Base_URL}{InvFileName}.csv'\n",
    "    InvestingData = pd.read_csv(File_URL)\n",
    "    InvestingData.drop(InvestingData.columns[[6]], axis=1, inplace=True)\n",
    "    InvestingData['Vol.'] = InvestingData['Vol.'].fillna(0)\n",
    "\n",
    "    # Convert Date string column to Date type\n",
    "    InvestingData['Date'] = pd.to_datetime(InvestingData['Date'], format='%m/%d/%Y')\n",
    "\n",
    "    # Set column 'Date' as the index\n",
    "    InvestingData.set_index('Date', inplace=True)\n",
    "\n",
    "    # Re-Arrange the columns to allign with that from Source 02 below.\n",
    "    # Using indexing notation\n",
    "    InvestingData = InvestingData[['Open', 'High', 'Low', 'Price', 'Vol.']]\n",
    "    InvestingData.rename(columns={\"Vol.\": \"Volume\"}, inplace=True)\n",
    "    \n",
    "    # Some of the data is formated in Thousands, thus having Commas.\n",
    "    # Remove commas and convert to float for specific columns\n",
    "    for Col in ['Price', 'Open', 'High', 'Low', 'Volume']:\n",
    "        if pd.api.types.is_object_dtype(InvestingData[Col]):\n",
    "            InvestingData[Col] = InvestingData[Col].str.replace(',', '').astype(float)\n",
    "\n",
    "    # Also sort the Data by Dates to allign with Source 02 below.\n",
    "    InvestingData.sort_values(by=['Date'], ascending=[True], inplace=True)\n",
    "    DataSource = InvestingData.copy()\n",
    "    print(\"Data Source in use is Investing.Com\")\n",
    "except Exception as e:\n",
    "    #print(f\"Error accessing GitHub path [{Base_URL}]: \\n{e}\")\n",
    "    # DATA SOURCE 02 (Tick Data Suite (TDS) stored in GitHub)\n",
    "    # ======================================================\n",
    "    # Reading data frame from csv file\n",
    "    DataFolder = 'TDS-Data/'\n",
    "    Base_URL = MyGitHubURL + DataFolder\n",
    "    Symbol = Major + Minor +'_'\n",
    "\n",
    "    # Check if the URL exists and is accessible\n",
    "    response = requests.head(Base_URL, timeout=5)\n",
    "    try:\n",
    "        #if response.status_code in SuccessCode:\n",
    "        # List to store DataFrames\n",
    "        Df_List = []\n",
    "\n",
    "        # Reading over 7,903,117 M1 data from GitHub\n",
    "        # Iterate through the years and read each .csv file into a DataFrame\n",
    "        for Year in range(2003, 2025):\n",
    "            File_URL = f'{Base_URL}{Symbol}{Year}.csv'\n",
    "            Df = pd.read_csv(File_URL)\n",
    "\n",
    "            Df_List.append(Df)\n",
    "\n",
    "        # Concatenate all DataFrames into one\n",
    "        CombinedDf = pd.concat(Df_List, ignore_index=True)\n",
    "        # Merge Date string and Time string, and convert to DateTime type\n",
    "        CombinedDf['DateTime'] = pd.to_datetime((CombinedDf['Date'] + \" \" + CombinedDf['Time']), format='%Y.%m.%d %H:%M:%S')\n",
    "        CombinedDf.drop(columns={'Date', 'Time'}, inplace=True)    \n",
    "        CombinedDf.set_index(CombinedDf['DateTime'], inplace=True)\n",
    "\n",
    "        # Stage 02\n",
    "        # Subsample data to one-day time steps, including weekends\n",
    "        DataOpen = CombinedDf.Open.resample('1D').first()\n",
    "        DataHigh = CombinedDf.High.resample('1D').max()\n",
    "        DataLow = CombinedDf.Low.resample('1D').min()\n",
    "        DataClose = CombinedDf.Close.resample('1D').last()\n",
    "        DataVolume = round(CombinedDf.TickVol.resample('1D').sum(), 2)\n",
    "\n",
    "        # Merge the Data on a common key, Date\n",
    "        TDSData = pd.merge(DataOpen, DataHigh, how='left', on=['DateTime'])\n",
    "        TDSData = pd.merge(TDSData, DataLow, how='left', on=['DateTime'])\n",
    "        TDSData = pd.merge(TDSData, DataClose, how='left', on=['DateTime'])\n",
    "        TDSData = pd.merge(TDSData, DataVolume, how='left', on=['DateTime'])\n",
    "\n",
    "        # Rename the index column to Date\n",
    "        TDSData.reset_index(inplace=True)\n",
    "        TDSData.rename(columns={'DateTime': 'Date', 'Close': 'Price', 'TickVol': 'Volume'}, inplace=True)\n",
    "        TDSData.set_index('Date', inplace=True)\n",
    "        TDSData.dropna(inplace = True)\n",
    "\n",
    "        # Also sort the Data by Dates to allign with Source 01 above.\n",
    "        TDSData.sort_values(by=['Date'], ascending=[True], inplace=True)\n",
    "        DataSource = TDSData.copy()\n",
    "        print(\"Data Source in use is TDS.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing GitHub path [{Base_URL}]: \\n{e}\")\n",
    "MinDate = DataSource.index.min()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b01aa99-ae87-4023-81ae-a7606d760a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Free the momory by deleting the DataFrames no longer needed\n",
    "del TDSData\n",
    "del Investing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15b235e-f73c-4a22-ae83-eacb4a5b7057",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSource.tail(7).sort_values(by=['Date'], ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4223c2ba-1525-4a5c-a1a9-5d1deea3a5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(DataSource))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897607de-73e2-447c-b780-32770a8b3ce2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Adding the Statistical Data to the DataSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b42dc92-8bcf-45d3-b734-dc77b86c9c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Calculate rolling averages, momentum indicators, etc.\n",
    "DataSource['SMA_20'] = DataSource['Price'].rolling(window=20).mean()\n",
    "DataSource['SMA_50'] = DataSource['Price'].rolling(window=50).mean()\n",
    "DataSource['RSI'] = Calculate_RSI(DataSource['Price'], window=14)\n",
    "DataSource['EMA_12'] = Calculate_EMA(DataSource['Price'], 12)\n",
    "DataSource['EMA_26'] = Calculate_EMA(DataSource['Price'], 26)\n",
    "DataSource['MACD'] = MACD(DataSource['Price']).macd()\n",
    "\n",
    "# Drop rows with missing values\n",
    "DataSource.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a06187-bf95-427b-8fdf-96cafa0415a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(DataSource))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53042766-b031-440b-88bc-0fcf1be9d09e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Get the MacroEconomics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d5732c-dcb2-4cb9-826a-7d05ccaac07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My FRED API key\n",
    "MyAPIKey = Fred(api_key='fb871b8abb01c472840cdd407ffd8dca')\n",
    "\n",
    "# This is the list of Indices we want to retrieve for USA and Canada\n",
    "MacroEconomic_Series_USA = {\n",
    "    'CPI': 'CPIAUCSL',  # Consumer Price Index (USA)\n",
    "    'IntRate': 'FEDFUNDS',  # Federal Funds Rate (USA)\n",
    "    'UnEmployRate': 'UNRATE',  # Unemployment Rate (USA)\n",
    "    'Imports': 'IMP0004',  # Imports (USA)\n",
    "    'Exports': 'EXP0004'  # Exports (USA)\n",
    "}\n",
    "\n",
    "MacroEconomic_Series_Canada = {\n",
    "    'CPI': 'CANCPIALLMINMEI',  # Consumer Price Index (Canada)\n",
    "    'IntRate': 'IR3TIB01CAM156N',  # Interest Rate (Canada)\n",
    "    'UnEmployRate': 'LRUNTTTTCAM156S',  # Unemployment Rate (Canada)\n",
    "    'Imports': 'XTIMVA01CAM667S',  # Imports (Canada)\n",
    "    'Exports': 'XTEXVA01CAM667S'  # Exports (Canada)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e304e95-4865-429c-ae5f-04a49d5bf7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get the MacroEconomics Data\n",
    "# Fetch data for USA\n",
    "USA_Data = []\n",
    "for IndName, Series_ID in MacroEconomic_Series_USA.items():\n",
    "    Data = Fetch_Series(MyAPIKey, IndName, Series_ID)\n",
    "    if (len(USA_Data) ==  0):\n",
    "        USA_Data = Data.copy()\n",
    "    else:\n",
    "        USA_Data = pd.merge(USA_Data, Data, on='Date')\n",
    "USA_Data.rename(columns={\"CPI\": \"USA_CPIs\", \"IntRate\": \"USA_IntRates\", \"UnEmployRate\": \"USA_UnEmployRates\", \"Imports\": \"USA_Imports\", \"Exports\": \"USA_Exports\"}, inplace=True)\n",
    "#USA_Data = USA_Data.drop_duplicates()\n",
    "\n",
    "\n",
    "# Fetch data for Canada\n",
    "Canada_Data = []\n",
    "for IndName, Series_ID in MacroEconomic_Series_Canada.items():\n",
    "    Data = Fetch_Series(MyAPIKey, IndName, Series_ID)\n",
    "    if (len(Canada_Data) ==  0):\n",
    "        Canada_Data = Data.copy()\n",
    "    else:\n",
    "        Canada_Data = pd.merge(Canada_Data, Data, on='Date')\n",
    "Canada_Data.rename(columns={\"CPI\": \"CAN_CPIs\", \"IntRate\": \"CAN_IntRates\", \"UnEmployRate\": \"CAN_UnEmployRates\", \"Imports\": \"CAN_Imports\", \"Exports\": \"CAN_Exports\"}, inplace=True)\n",
    "#Canada_Data = Canada_Data.drop_duplicates()\n",
    "\n",
    "# Merge the MacroEconomic datasets on a common key, such as Date\n",
    "MacroEcons = pd.merge(USA_Data, Canada_Data, on='Date')\n",
    "\n",
    "# Free the memory.\n",
    "#del USA_Data, Canada_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a471f3-fd75-46f7-a7d6-e90cdf014b9b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Mering the MacroEconomics Data with the DataSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eff0a7-0e24-4ced-866d-bb92bcd78f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Merge the DataSource with the MacroEconomic dataset on a common key, such as Date\n",
    "Complete_Data = pd.merge(DataSource, MacroEcons, how='left', on=['Date'])\n",
    "\n",
    "# Set NaN to Zero, and column 'Date' as the index\n",
    "Complete_Data.fillna(0, inplace=True)\n",
    "Complete_Data.set_index('Date', inplace=True)\n",
    "\n",
    "# Free the memory.\n",
    "#del DataSource, MacroEcons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d399f2-46ae-4d60-827b-fb56d808d2fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90f3c21-01da-42bc-b898-0421904bf170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the Performance Metrics to a DataFrame for easy comparism.\n",
    "# Define column names\n",
    "Cols = ['ModelName', 'ModelCode', 'MAE', 'MSE', 'RMSE', 'R2_Train', 'R2_Test', 'Comment']\n",
    "\n",
    "# Create DataFrame\n",
    "Models_Compare = pd.DataFrame(columns = Cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87c9b46-8939-46c0-bcab-deecdbb51aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Common/Global parameters & Modules\n",
    "# Here, I choose to use 85% of my data for Training and the remaing 15% for Testing.\n",
    "TestPercent = 0.15\n",
    "TrainPercent = 1.0 - TestPercent\n",
    "\n",
    "# Predictions\n",
    "PredDays = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fcbe30-477f-48a2-8b53-9937dd719cca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Creating Label column for the Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de103d-6cb0-44a8-87f0-ae87a283199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 'Label' column for the forecast\n",
    "Complete_Data['Label'] = Complete_Data['Price'].shift(-(PredDays))\n",
    "Complete_Data.dropna(inplace=True)\n",
    "MaxDate = Complete_Data.index.max()\n",
    "\n",
    "ActualValues = Complete_Data['Label'][-(PredDays):].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fe8a82-6af6-4704-9f77-2fb9557ee5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Complete_Data.tail(8).sort_values(by=['Date'], ascending=[False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad126be9-6873-4081-b7c9-0636af436014",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Split the Data, Scale, and Plot Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100741b9-acd6-4777-b6a4-6541d8be3839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train/test (85/15 ratio) with caution for time series\n",
    "Complete_Data.dropna(inplace=True)\n",
    "Split_Position = int(len(Complete_Data) * TrainPercent)\n",
    "Train_Data, Test_Data = Complete_Data.iloc[:Split_Position], Complete_Data.iloc[Split_Position:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff3b4e-d6e1-425b-95f7-0ba4a61609c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the MinMaxScaler\n",
    "Scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fit the scaler only on the training data\n",
    "Scaler.fit(Train_Data)\n",
    "\n",
    "# Transform both the training and test data using the same scaler\n",
    "Train_Data_Scaled = Scaler.transform(Train_Data)\n",
    "Test_Data_Scaled = Scaler.transform(Test_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dce326-8ef0-4f0a-8d9f-fde3c826408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the scaled data back into a DataFrame for easy inspection\n",
    "Train_Data_Scaled_Df = pd.DataFrame(Train_Data_Scaled, index=Train_Data.index, columns=Train_Data.columns)\n",
    "Test_Data_Scaled_Df = pd.DataFrame(Test_Data_Scaled, index=Test_Data.index, columns=Test_Data.columns)\n",
    "\n",
    "# Handle missing values\n",
    "Train_Data_Scaled_Df.dropna(inplace=True)\n",
    "Test_Data_Scaled_Df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277d3a1e-46ac-4749-8f33-d3bea75ac40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match into Training and Testing data\n",
    "X_train, y_train = Train_Data_Scaled_Df, Train_Data['Label']\n",
    "X_test, y_test = Test_Data_Scaled_Df, Test_Data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7acc356-318e-46c7-89d5-9a2392244ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Train/Test Data\n",
    "Plot_TrainTest(CrncyPair, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe9307f-a385-40f4-8ec7-f4c1e9a64dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c422e425-c192-4347-8845-f9d6c642d8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18e1d15d-70a3-4150-acd2-2bcc8ed5e9b2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18d70d3-a465-4010-88f2-2a5107f4eede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbbaf55-3550-4e25-a1f1-bcd76ef998f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f275db18-7a5f-4025-8b97-b6626791d4d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking how good this Model will be\n",
    "R2_Train, R2_Test, Comment = TestTheModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91697a9-6355-4a94-8e23-816c8d22b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "future_predictions = y_pred[-(PredDays):]\n",
    "LNR = future_predictions\n",
    "\n",
    "# Evaluate and Report Accuracy, Predict the future, and Plot the graph.\n",
    "ModelCode = 'LNR'\n",
    "ModelName = 'Linear Regression'\n",
    "Rpt_Evaluate_Plot(CrncyPair, ModelName, ModelCode, R2_Train, R2_Test, Comment, y_train, y_test, y_pred, MaxDate, future_predictions)\n",
    "\n",
    "# Delete the following objects so as to free the memory, and also Re-Set the objects for the next Model.\n",
    "del model, y_pred, future_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a1133a-1cb6-4870-81bc-6a756d8197b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1410fe7c-eedd-4b10-acd2-bcfc451e613a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebc5a2cc-b3ef-454e-8151-5ad37b247381",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Random Forest Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f2a8c0-23b3-46b8-98a2-bb00eefb8922",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabaa2d7-ef5b-4d82-8117-bb8d58062128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Random Forest model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=None)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655edeb1-ce9b-4e92-81d6-b668908229d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how good this Model will be\n",
    "R2_Train, R2_Test, Comment  = TestTheModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75afa4de-754e-4815-8132-2edf4eefbd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "future_predictions = y_pred[-(PredDays):]\n",
    "RFR = future_predictions\n",
    "\n",
    "# Evaluate and Report Accuracy, Predict the future, and Plot the graph.\n",
    "ModelCode = 'RFR'\n",
    "ModelName = 'Random Forest Regressor'\n",
    "Rpt_Evaluate_Plot(CrncyPair, ModelName, ModelCode, R2_Train, R2_Test, Comment, y_train, y_test, y_pred, MaxDate, future_predictions)\n",
    "\n",
    "# Delete the following objects so as to free the memory, and also Re-Set the objects for the next Model.\n",
    "del model, y_pred, future_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e746b30-d1c8-4287-a94e-b9f8b20ea66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64343cb6-3d83-4e26-855c-e9427c4dd4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7eeebc1-e5d2-47b3-845d-17bdc9b12853",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0180b31e-fcbb-4542-8ff2-e6a5db91a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a96baaf-fa4a-46e7-8899-3c6ac6dbd9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',   # Use squared error loss for regression\n",
    "    'max_depth': 6,                    # Maximum depth of trees\n",
    "    'learning_rate': 0.1,              # Learning rate {0.1}\n",
    "    'n_estimators': 100,               # Number of boosting rounds (trees)\n",
    "    'seed': 42                         # Random seed for reproducibility {42}\n",
    "}\n",
    "\n",
    "# Instantiate XGBoost regressor\n",
    "xgb_model = xgb.XGBRegressor(**params)\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7637403b-14ae-4a94-aab3-8c612f24e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how good this Model will be\n",
    "R2_Train, R2_Test, Comment = TestTheModel(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b359136-2f4d-4d2c-858b-c8f52ff95558",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make predictions on the testing set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "future_predictions = y_pred[-(PredDays):]\n",
    "XGB = future_predictions\n",
    "\n",
    "# Evaluate and Report Accuracy, Predict the future, and Plot the graph.\n",
    "ModelCode = 'XGB'\n",
    "ModelName = 'XGBoost Regression'\n",
    "Rpt_Evaluate_Plot(CrncyPair, ModelName, ModelCode, R2_Train, R2_Test, Comment, y_train, y_test, y_pred, MaxDate, future_predictions)\n",
    "\n",
    "# Delete the following objects so as to free the memory, and also Re-Set the objects for the next Model.\n",
    "del xgb_model, y_pred, future_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3403a9d5-3df1-4b43-b86e-08e49d17dfaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fa52ca-f3e6-46ba-b60a-87751190a90d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da241e0c-183f-45db-bf9c-bf5354f0baed",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1beb380-c0a4-4351-aa97-3872eaae9eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea0b44e-5336-4afe-be14-dac29a60f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit the Ridge Regression model\n",
    "alpha = 0.1  # Regularization strength (hyperparameter to be tuned)\n",
    "model = Ridge(alpha=alpha)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09392e8f-5c28-4c02-a748-00a85f47a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how good this Model will be\n",
    "R2_Train, R2_Test, Comment = TestTheModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842cfe4f-0347-4fc0-9632-a7cdbcf8f434",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "future_predictions = y_pred[-(PredDays):]\n",
    "RIR = future_predictions\n",
    "\n",
    "# Evaluate and Report Accuracy, Predict the future, and Plot the graph.\n",
    "ModelCode = 'RIR'\n",
    "ModelName = 'Ridge Regression'\n",
    "Rpt_Evaluate_Plot(CrncyPair, ModelName, ModelCode, R2_Train, R2_Test, Comment, y_train, y_test, y_pred, MaxDate, future_predictions)\n",
    "\n",
    "# Delete the following objects so as to free the memory, and also Re-Set the objects for the next Model.\n",
    "del model, y_pred, future_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c0933-451c-4b93-9906-ebca5f676f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11286f99-1080-4cc1-9ac1-e42907532bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "068669ce-b599-4fdc-b97e-6657730084c6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Lasso Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcbb25f-f519-4420-900c-de7409ea4496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2922b8c2-b625-4573-a7f8-c114c503a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit the Lasso Regression model\n",
    "alpha = 0.1  # Regularization strength (hyperparameter to be tuned)\n",
    "model = Lasso(alpha=alpha)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af677836-cc8f-4ef8-949e-1956046660b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how good this Model will be\n",
    "R2_Train, R2_Test, Comment = TestTheModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45841833-1906-437f-b38f-ca28a5d3b90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "future_predictions = y_pred[-(PredDays):]\n",
    "LAR = future_predictions\n",
    "\n",
    "# Evaluate and Report Accuracy, Predict the future, and Plot the graph.\n",
    "ModelCode = 'LAR'\n",
    "ModelName = 'Lasso Regression'\n",
    "Rpt_Evaluate_Plot(CrncyPair, ModelName, ModelCode, R2_Train, R2_Test, Comment, y_train, y_test, y_pred, MaxDate, future_predictions)\n",
    "\n",
    "# Delete the following objects so as to free the memory, and also Re-Set the objects for the next Model.\n",
    "del model, y_pred, future_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828bc961-fe66-4bf0-9543-3232f8af857c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec8a74a-95e6-44fe-b6cf-2e674e917cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5937988b-fc1e-4f94-997e-33ab108976c0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Support Vector Regression (SVR) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8a78f4-ac6f-42a4-a1bd-0d3afe3ab968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d2a7d-c0b0-4ff5-bc9e-7084aaeb771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.2)\n",
    "svr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3aa60b-6f69-436e-a7a0-3a4ccc152c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how good this Model will be\n",
    "R2_Train, R2_Test, Comment = TestTheModel(svr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd0f20-4bf8-405a-bce8-d07d9546f9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make predictions on the testing set\n",
    "y_pred = svr_model.predict(X_test)\n",
    "future_predictions = y_pred[-(PredDays):]\n",
    "SVR = future_predictions\n",
    "\n",
    "# Evaluate and Report Accuracy, Predict the future, and Plot the graph.\n",
    "ModelCode = 'SVR'\n",
    "ModelName = 'Support Vector Regression'\n",
    "Rpt_Evaluate_Plot(CrncyPair, ModelName, ModelCode, R2_Train, R2_Test, Comment, y_train, y_test, y_pred, MaxDate, future_predictions)\n",
    "\n",
    "# Delete the following objects so as to free the memory, and also Re-Set the objects for the next Model.\n",
    "del svr_model, y_pred, future_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619bdaf8-411e-4dc8-b1c0-9672139b6512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af7a78a-7243-49b3-acfe-608191d7fd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "facf9c8c-c5c5-47fe-adfa-4466f21d408a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Bayesian Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b428304-3103-4056-b6d5-4940a1070b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d5ba46-c8e9-4f7b-9daa-9739a1e28a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "Baye_model = BayesianRidge()\n",
    "Baye_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a639dc0b-5e51-452a-8ab4-57e0d64d0a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how good this Model will be\n",
    "R2_Train, R2_Test, Comment = TestTheModel(Baye_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81be678c-8133-41b2-bfd0-19ef52e3073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make predictions on the testing set\n",
    "y_pred = Baye_model.predict(X_test)\n",
    "future_predictions = y_pred[-(PredDays):]\n",
    "BRR = future_predictions\n",
    "\n",
    "# Evaluate and Report Accuracy, Predict the future, and Plot the graph.\n",
    "ModelCode = 'BRR'\n",
    "ModelName = 'Bayesian Ridge Regression'\n",
    "Rpt_Evaluate_Plot(CrncyPair, ModelName, ModelCode, R2_Train, R2_Test, Comment, y_train, y_test, y_pred, MaxDate, future_predictions)\n",
    "\n",
    "# Delete the following objects so as to free the memory, and also Re-Set the objects for the next Model.\n",
    "del Baye_model, y_pred, future_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13070984-56c1-4d6a-ad64-a233daa569db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7edaf9-7f61-4eea-94b1-40fff4f27c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45e1a334-07ec-4163-90d9-3d68d8fdc41b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### AdaBoost Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2117e8eb-8570-4a6f-bf92-460d78a260aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773df6f9-7971-4c10-b707-1e3107cd0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaB_model = AdaBoostRegressor(n_estimators=100, random_state=None)\n",
    "AdaB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f9bc9c-37ee-4b8d-80ce-ca9a29d8de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how good this Model will be\n",
    "R2_Train, R2_Test, Comment = TestTheModel(AdaB_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8256ce-4266-4026-88b1-ab434e835fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make predictions on the testing set\n",
    "y_pred = AdaB_model.predict(X_test)\n",
    "future_predictions = y_pred[-(PredDays):]\n",
    "ABR = future_predictions\n",
    "\n",
    "# Evaluate and Report Accuracy, Predict the future, and Plot the graph.\n",
    "ModelCode = 'ABR'\n",
    "ModelName = 'AdaBoost Regression'\n",
    "Rpt_Evaluate_Plot(CrncyPair, ModelName, ModelCode, R2_Train, R2_Test, Comment, y_train, y_test, y_pred, MaxDate, future_predictions)\n",
    "\n",
    "# Delete the following objects so as to free the memory, and also Re-Set the objects for the next Model.\n",
    "del AdaB_model, y_pred, future_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e9d915-62f1-49da-8ac9-f62dfe6e5ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf4c007-effc-4632-bec1-bf135d90f945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa872649-4b70-4bb6-b7f1-aa847e790e3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Summary of the model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241bedc8-78d2-453b-8b53-0505c00ac1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Models_Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39758f-2172-4b41-9df8-17f50b22f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "Models_Compare[['ModelName','MAE','MSE','RMSE','R2_Train','R2_Test', 'Comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27efa69-1089-4d33-9619-3ab5468e04dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6432e0-7da5-4d56-8ede-0bbc4e62f1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593ed01a-c0b4-4d8a-8749-f3f94ce7cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the graph\n",
    "Future_Dates = pd.date_range(start=MaxDate+timedelta(days=1), periods=PredDays, freq=\"B\")\n",
    "\n",
    "# Plot Actual vs Predicted prices\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(Future_Dates, ActualValues, label='Actual Data', color='green')\n",
    "plt.plot(Future_Dates, LNR, label='Linear Regression', color='blue')\n",
    "plt.plot(Future_Dates, RFR, label='Random Forest Regressor', color='red')\n",
    "plt.plot(Future_Dates, XGB, label='XGBoost Regression', color='yellow')\n",
    "plt.plot(Future_Dates, RIR, label='Ridge Regression', color='orange')\n",
    "#plt.plot(Future_Dates, LAR, label='Lasso Regression', color='black')\n",
    "#plt.plot(Future_Dates, SVR, label='Support Vector Regression', color='magenta')\n",
    "plt.plot(Future_Dates, BRR, label='Bayesian Ridge Regression', color='cyan')\n",
    "plt.plot(Future_Dates, ABR, label='AdaBoost Regression', color='purple')\n",
    "plt.scatter(Future_Dates, ActualValues, s=10, color='red')\n",
    "plt.scatter(Future_Dates, LNR, s=10, color='red')\n",
    "plt.scatter(Future_Dates, RFR, s=10, color='red')\n",
    "plt.scatter(Future_Dates, XGB, s=10, color='red')\n",
    "plt.scatter(Future_Dates, RIR, s=10, color='red')\n",
    "#plt.scatter(Future_Dates, LAR, s=10, color='red')\n",
    "#plt.scatter(Future_Dates, SVR, s=10, color='red')\n",
    "plt.scatter(Future_Dates, BRR, s=10, color='red')\n",
    "plt.scatter(Future_Dates, ABR, s=10, color='red')\n",
    "plt.title('Actual vs All Predicted Models for ' + CrncyPair + ' Forecasting')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3313b5-f9d0-4260-a471-be0bf84e8741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free the Memory\n",
    "#del FxPair_Data, X, y, X_train, X_test, y_train, y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
